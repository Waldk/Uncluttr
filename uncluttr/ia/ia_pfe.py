# -*- coding: utf-8 -*-
"""IA PFE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1shd8M_YKK_X3xRpzT44JosxCAr2g-NAQ
"""

# !pip install pytesseract
# !pip install pdf2image
# !pip install transformers
# !pip install spacy
# !python -m spacy download fr_core_news_sm
# !apt-get install -y poppler-utils
# !apt-get install -y tesseract-ocr-fra

import re
import spacy
import fitz  # PyMuPDF pour lire les PDF
import easyocr  # OCR sans Tesseract
from collections import Counter
import os

# Charger le modèle de langue français de spaCy
nlp = spacy.load("fr_core_news_sm")

def check_and_download_dependencies():
    try:
        spacy.cli.download("fr_core_news_sm")
    except Exception as e:
        print("Erreur lors du téléchargement du modèle spaCy:", e)

check_and_download_dependencies()

# Liste de mots-clés pour chaque type de document
document_keywords = {
    "Procédure, méthode, guide": ["procédure", "méthode", "guide", "instructions", "étapes", "processus", "fonctionnement"],
    "CV": ["compétences", "expérience", "formation", "objectif", "parcours", "CV", "candidat", "recrutement"],
    "Lettre de motivation": ["motivation", "candidature", "poste", "entreprise", "recrutement", "compétences", "intérêt", "travailler"],
    "Contrat": ["accord", "engagement", "clause", "signature", "responsabilité", "conditions", "parties"],
    "Fiche de paie": ["salaire", "net", "brut", "cotisations", "charges sociales", "rémunération"],
    "Devis": ["estimation", "prix", "proposition", "offre", "coût", "service", "quantité"],
    "Facture": ["facture", "paiement", "montant", "produit", "service", "date", "référence"],
    "Bon de commandes": ["commande", "produit", "quantité", "prix", "bon", "livraison"],
    "Attestation": ["attestation", "certification", "déclaration", "preuve", "confirmation"]
}

def extract_text_from_pdf(pdf_path):
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(f"Le fichier spécifié n'existe pas : {pdf_path}")
    doc = fitz.open(pdf_path)
    text = ""
    for page in doc:
        text += page.get_text()
    doc.close()
    return text

def ocr_with_easyocr(pdf_path):
    reader = easyocr.Reader(["fr"])
    results = reader.readtext(pdf_path, detail=0)
    return " ".join(results)

def preprocess_text(text):
    """Nettoie le texte, applique la lemmatisation et extrait les noms, verbes et adjectifs."""
    text = re.sub(r'[^a-zA-Z\s]', '', text.lower())
    doc = nlp(text)
    words = [token.lemma_ for token in doc if token.pos_ in {"NOUN", "VERB", "ADJ"} and not token.is_stop]
    return words

def generate_theme(words):
    """Génère un thème basé sur les mots les plus fréquents."""
    word_counts = Counter(words)
    most_common = word_counts.most_common(5)
    theme = " | ".join([word[0] for word in most_common])
    return f"Thème potentiel : {theme}"

def choose_document_tag(frequent_words):
    """Identifie la catégorie du document en fonction des mots-clés."""
    document_tags = []
    for tag, keywords in document_keywords.items():
        common_keywords = [word for word in frequent_words if word in keywords]
        if common_keywords:
            document_tags.append((tag, len(common_keywords)))
    if document_tags:
        document_tags.sort(key=lambda x: x[1], reverse=True)
        return document_tags[0][0]
    return "Document inconnu"

def extract_text_from_document(pdf_path):
    """Extrait le texte d'un document PDF, avec OCR si nécessaire."""
    extracted_text = extract_text_from_pdf(pdf_path)
    if not extracted_text.strip():
        extracted_text = ocr_with_easyocr(pdf_path)
    return extracted_text

def analyze_text_from_document(pdf_path):
    """Extrait, prétraite et analyse le texte pour générer un thème et identifier la catégorie du document."""
    text = extract_text_from_document(pdf_path)
    words = preprocess_text(text)
    theme = generate_theme(words)
    document_tag = choose_document_tag(words)
    print(theme)
    print("Le document appartient à la catégorie :", document_tag)

if __name__ == "__main__":
    pdf_path = "C:/Users/cerin/OneDrive/Bureau/modele-planning-ing4-ap.pdf"
    analyze_text_from_document(pdf_path)

